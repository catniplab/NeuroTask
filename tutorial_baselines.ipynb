{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_neurotask import *\n",
    "from baselines.metrics import get_R2\n",
    "from baselines.decoders import *\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = 'NeuroTask/2_10_Chowdhury_CObump.parquet'\n",
    "df,bin = load_and_filter_parquet(parquet_file_path,['A', 'I','F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = rebin(df,prev_bin_size = bin ,new_bin_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, y_train_list, X_val_list, y_val_list, X_test_list, y_test_list = process_data(df10, bins_before=5, \n",
    "                                                 training_range=[0, 0.7], valid_range=[0.7, 0.8], testing_range=[0.8, 1], \n",
    "                                                 behavior_columns=['hand_vel_x', 'hand_vel_y'],zscore = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", sum(X.shape[2] for X in X_train_list), \"unique neurons in the dataset in\",len(X_train_list),\"different sessions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiener Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_list)):\n",
    "    X_flat_train=X_train_list[i].reshape(X_train_list[i].shape[0],(X_train_list[i].shape[1]*X_train_list[i].shape[2]))\n",
    "\n",
    "    X_flat_test = X_test_list[i].reshape(X_test_list[i].shape[0],(X_test_list[i].shape[1]*X_test_list[i].shape[2]))\n",
    "\n",
    "    #Declare model\n",
    "    model_wf=WienerFilterDecoder()\n",
    "\n",
    "    #Fit model|\n",
    "    model_wf.fit(X_flat_train,y_train_list[i])\n",
    "\n",
    "    #Get predictions\n",
    "    y_valid_predicted_wf=model_wf.predict(X_flat_test)\n",
    "\n",
    "    #Get metric of fit\n",
    "    R2s_wf=get_R2(y_test_list[i],y_valid_predicted_wf)\n",
    "    print('session', i+1,'R2s:', R2s_wf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiener Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_list)):\n",
    "    #for i in range(len(X_train_list)):\n",
    "    X_flat_train=X_train_list[i].reshape(X_train_list[i].shape[0],(X_train_list[i].shape[1]*X_train_list[i].shape[2]))\n",
    "\n",
    "    X_flat_test = X_test_list[i].reshape(X_test_list[i].shape[0],(X_test_list[i].shape[1]*X_test_list[i].shape[2]))\n",
    "\n",
    "    #Declare model\n",
    "    model_wf=WienerCascadeDecoder(degree=3)\n",
    "\n",
    "    #Fit model\n",
    "    model_wf.fit(X_flat_train,y_train_list[i])\n",
    "\n",
    "    #Get predictions\n",
    "    y_valid_predicted_wf=model_wf.predict(X_flat_test)\n",
    "\n",
    "    #Get metric of fit\n",
    "    R2s_wf=get_R2(y_test_list[i],y_valid_predicted_wf)\n",
    "    print('session', i+1,'R2s:', R2s_wf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_dnn=DenseNNDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_dnn.fit(X_train,y_train)\n",
    "            y_valid_predicted_dnn=model_dnn.predict(X_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_list)):   \n",
    "        print('session ',i+1)   \n",
    "\n",
    "        X_train = X_train_list[i].reshape(X_train_list[i].shape[0],(X_train_list[i].shape[1]*X_train_list[i].shape[2]))\n",
    "        X_valid = X_val_list[i].reshape(X_val_list[i].shape[0],(X_val_list[i].shape[1]*X_val_list[i].shape[2]))\n",
    "        y_train = y_train_list[i]\n",
    "        y_valid = y_val_list[i] \n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        dnnBO = BayesianOptimization(dnn_evaluate, {'num_units': (50, 500), 'frac_dropout': (0,.5), 'n_epochs': (2,200)})\n",
    "        #lstmBO.maximize(init_points=20, n_iter=20, kappa=10)\n",
    "        utility = UtilityFunction(kind=\"ucb\", kappa=10, xi=0.0)\n",
    "        dnnBO.maximize(init_points=10,n_iter=5)\n",
    "\n",
    "        best_params=dnnBO.max['params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=int(best_params['n_epochs'])\n",
    "        num_units=int(best_params['num_units'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 #session\n",
    "\n",
    "X_flat_train=X_train_list[i].reshape(X_train_list[i].shape[0],(X_train_list[i].shape[1]*X_train_list[i].shape[2]))\n",
    "\n",
    "X_flat_test = X_test_list[i].reshape(X_test_list[i].shape[0],(X_test_list[i].shape[1]*X_test_list[i].shape[2]))\n",
    "\n",
    "model_dnn=DenseNNDecoder(units=200,dropout=0.25,num_epochs=5)\n",
    "\n",
    "#Fit model\n",
    "model_dnn.fit(X_flat_train,y_train_list[i])\n",
    "\n",
    "#Get predictions\n",
    "y_test_predicted_dnn=model_dnn.predict(X_flat_test)\n",
    "\n",
    "#Get metric of fit\n",
    "R2s_dnn=get_R2(y_test_list[i],y_test_predicted_dnn)\n",
    "print('session', i+1,'R2s:', R2s_dnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_lstm=LSTMDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_lstm.fit(X_train,y_train)\n",
    "            y_valid_predicted_lstm=model_lstm.predict(X_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_list)):\n",
    "        print('session ',i+1)\n",
    "        X_train = X_train_list[i]\n",
    "        X_valid = X_val_list[i]\n",
    "        y_train = y_train_list[i]\n",
    "        y_valid = y_val_list[i]\n",
    "                \n",
    "        #Do bayesian optimization\n",
    "        lstmBO = BayesianOptimization(lstm_evaluate, {'num_units': (50, 500), 'frac_dropout': (0,.5), 'n_epochs': (2,25)})\n",
    "        #lstmBO.maximize(init_points=20, n_iter=20, kappa=10)\n",
    "        utility = UtilityFunction(kind=\"ucb\", kappa=10, xi=0.0)\n",
    "        lstmBO.maximize(init_points=10,n_iter=5)\n",
    "\n",
    "        best_params=lstmBO.max['params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=int(best_params['n_epochs'])\n",
    "        num_units=int(best_params['num_units'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the performance in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session id\n",
    "i = 0\n",
    "\n",
    "model_lstm=LSTMDecoder(units=210,dropout=0.37,num_epochs=23)\n",
    "\n",
    "#Fit model\n",
    "model_lstm.fit(X_train_list[i],y_train_list[i])\n",
    "\n",
    "#Get predictions\n",
    "y_test_predicted_lstm=model_lstm.predict(X_test_list[i])\n",
    "\n",
    "#Get metric of fit\n",
    "R2s_lstm=get_R2(y_test_list[i],y_test_predicted_lstm)\n",
    "print('session', i+1,'R2s:', R2s_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
